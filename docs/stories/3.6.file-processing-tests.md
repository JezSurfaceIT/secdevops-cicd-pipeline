# Story 3.6: Setup File Processing Tests

**Epic:** 3 - Test Environment & Automation  
**Story Number:** 3.6  
**Title:** Implement File API Testing with Various Formats  
**Status:** READY  
**Points:** 3  
**Components:** 421-423 (File Processing)  

---

## Story

**As a** QA Engineer,  
**I want** comprehensive file processing test capabilities,  
**so that** we can validate file upload, processing, and storage across all supported formats.

---

## Acceptance Criteria

1. File Processing API deployed and configured (421)
2. Test file store with various formats populated (422)
3. Test harness for file operations created (423)
4. Support for common formats (PDF, CSV, JSON, XML, images)
5. File validation and virus scanning tested
6. Large file handling tested (up to 1GB)
7. Concurrent upload testing capability
8. Performance metrics for file operations

---

## Tasks / Subtasks

### Task 1: Write File Processing Tests (TDD) (AC: 1, 4, 5)
- [ ] Create `file-processing/api_test.go`
  - [ ] Test file upload endpoint
  - [ ] Test format validation
  - [ ] Test virus scanning
  - [ ] Test storage operations
- [ ] Run tests to confirm they fail (Red phase)

### Task 2: Deploy File Processing API (AC: 1)
- [ ] Create file processing service
  ```javascript
  // file-api/server.js
  const express = require('express');
  const multer = require('multer');
  const { BlobServiceClient } = require('@azure/storage-blob');
  const clamav = require('clamav.js');
  
  const app = express();
  const scanner = new clamav.ClamAV();
  
  // Configure multer for file uploads
  const storage = multer.memoryStorage();
  const upload = multer({
    storage,
    limits: {
      fileSize: 1024 * 1024 * 1024, // 1GB
      files: 10
    },
    fileFilter: async (req, file, cb) => {
      // Validate file type
      const allowed = await validateFileType(file);
      if (!allowed) {
        cb(new Error(`File type ${file.mimetype} not allowed`));
      } else {
        cb(null, true);
      }
    }
  });
  
  // File upload endpoint
  app.post('/api/files/upload', upload.single('file'), async (req, res) => {
    try {
      const file = req.file;
      
      // Virus scan
      const scanResult = await scanner.scanBuffer(file.buffer);
      if (scanResult.isInfected) {
        return res.status(400).json({
          error: 'File infected',
          virus: scanResult.viruses
        });
      }
      
      // Process file based on type
      const result = await processFile(file);
      
      // Store in blob storage
      const storageResult = await storeFile(file, result);
      
      res.json({
        id: storageResult.id,
        filename: file.originalname,
        size: file.size,
        type: file.mimetype,
        processed: result,
        url: storageResult.url
      });
    } catch (error) {
      res.status(500).json({ error: error.message });
    }
  });
  
  async function processFile(file) {
    const processors = {
      'application/pdf': processPDF,
      'text/csv': processCSV,
      'application/json': processJSON,
      'text/xml': processXML,
      'image/jpeg': processImage,
      'image/png': processImage
    };
    
    const processor = processors[file.mimetype];
    if (!processor) {
      throw new Error(`No processor for ${file.mimetype}`);
    }
    
    return await processor(file);
  }
  ```
- [ ] Configure file storage
- [ ] Setup virus scanning
- [ ] Implement format validators

### Task 3: Create Test File Store (AC: 2, 4)
- [ ] Generate test files
  ```javascript
  // test-files/generator.js
  const fs = require('fs');
  const path = require('path');
  const PDFDocument = require('pdfkit');
  const sharp = require('sharp');
  const faker = require('faker');
  
  class TestFileGenerator {
    async generateAll(outputDir) {
      await this.generatePDFs(outputDir);
      await this.generateCSVs(outputDir);
      await this.generateJSONs(outputDir);
      await this.generateXMLs(outputDir);
      await this.generateImages(outputDir);
      await this.generateLargeFiles(outputDir);
      await this.generateCorruptedFiles(outputDir);
    }
    
    async generatePDFs(outputDir) {
      // Valid PDF
      const doc = new PDFDocument();
      doc.pipe(fs.createWriteStream(path.join(outputDir, 'valid.pdf')));
      doc.text('This is a valid PDF document for testing');
      doc.end();
      
      // PDF with forms
      const formDoc = new PDFDocument();
      formDoc.pipe(fs.createWriteStream(path.join(outputDir, 'form.pdf')));
      formDoc.text('Form Document');
      // Add form fields
      formDoc.end();
      
      // Encrypted PDF
      const encDoc = new PDFDocument({
        userPassword: 'user123',
        ownerPassword: 'owner123',
        permissions: {
          printing: 'highResolution',
          modifying: false,
          copying: false
        }
      });
      encDoc.pipe(fs.createWriteStream(path.join(outputDir, 'encrypted.pdf')));
      encDoc.text('Encrypted content');
      encDoc.end();
    }
    
    async generateCSVs(outputDir) {
      // Valid CSV
      const validCSV = [
        'id,name,email,age',
        '1,John Doe,john@example.com,30',
        '2,Jane Smith,jane@example.com,25'
      ].join('\n');
      fs.writeFileSync(path.join(outputDir, 'valid.csv'), validCSV);
      
      // Large CSV (1M rows)
      const largeCSV = ['id,name,email,age'];
      for (let i = 0; i < 1000000; i++) {
        largeCSV.push(`${i},${faker.name.findName()},${faker.internet.email()},${faker.datatype.number()}`);
      }
      fs.writeFileSync(path.join(outputDir, 'large.csv'), largeCSV.join('\n'));
      
      // Malformed CSV
      const malformedCSV = [
        'id,name,email',
        '1,"Unclosed quote,john@example.com',
        '2,Jane,jane@example.com,extra,columns'
      ].join('\n');
      fs.writeFileSync(path.join(outputDir, 'malformed.csv'), malformedCSV);
    }
    
    async generateImages(outputDir) {
      // Valid JPEG
      await sharp({
        create: {
          width: 1920,
          height: 1080,
          channels: 3,
          background: { r: 255, g: 0, b: 0 }
        }
      })
      .jpeg()
      .toFile(path.join(outputDir, 'valid.jpg'));
      
      // Valid PNG with transparency
      await sharp({
        create: {
          width: 800,
          height: 600,
          channels: 4,
          background: { r: 0, g: 255, b: 0, alpha: 0.5 }
        }
      })
      .png()
      .toFile(path.join(outputDir, 'transparent.png'));
      
      // EXIF data image
      await sharp(path.join(outputDir, 'valid.jpg'))
        .withMetadata({
          exif: {
            IFD0: {
              Copyright: 'Test Copyright',
              XPAuthor: 'Test Author'
            }
          }
        })
        .toFile(path.join(outputDir, 'with-exif.jpg'));
    }
  }
  ```
- [ ] Create malicious test files
- [ ] Generate edge case files
- [ ] Setup file fixtures

### Task 4: Build Test Harness (AC: 3, 7)
- [ ] Create test harness framework
  ```javascript
  // test-harness/file-harness.js
  class FileTestHarness {
    constructor(apiUrl) {
      this.apiUrl = apiUrl;
      this.results = [];
    }
    
    async runAllTests() {
      await this.testValidFiles();
      await this.testInvalidFiles();
      await this.testLargeFiles();
      await this.testConcurrentUploads();
      await this.testVirusScanning();
      await this.testPerformance();
      
      return this.generateReport();
    }
    
    async testValidFiles() {
      const files = [
        'valid.pdf',
        'valid.csv',
        'valid.json',
        'valid.xml',
        'valid.jpg',
        'valid.png'
      ];
      
      for (const file of files) {
        const result = await this.uploadFile(file);
        this.results.push({
          test: 'valid_file_upload',
          file,
          success: result.status === 200,
          duration: result.duration,
          details: result.data
        });
      }
    }
    
    async testConcurrentUploads() {
      const files = Array(10).fill('valid.pdf');
      const startTime = Date.now();
      
      const promises = files.map((file, index) => 
        this.uploadFile(file, `concurrent-${index}.pdf`)
      );
      
      const results = await Promise.allSettled(promises);
      const duration = Date.now() - startTime;
      
      this.results.push({
        test: 'concurrent_uploads',
        count: files.length,
        success: results.filter(r => r.status === 'fulfilled').length,
        failed: results.filter(r => r.status === 'rejected').length,
        duration,
        throughput: (files.length / duration) * 1000
      });
    }
    
    async testVirusScanning() {
      // EICAR test file (standard antivirus test string)
      const eicar = 'X5O!P%@AP[4\\PZX54(P^)7CC)7}$EICAR-STANDARD-ANTIVIRUS-TEST-FILE!$H+H*';
      
      const result = await this.uploadRawContent(eicar, 'virus-test.txt');
      
      this.results.push({
        test: 'virus_scanning',
        success: result.status === 400 && result.data.error === 'File infected',
        detected: result.data.virus,
        duration: result.duration
      });
    }
    
    async testPerformance() {
      const sizes = [
        { size: '1MB', file: 'test-1mb.bin' },
        { size: '10MB', file: 'test-10mb.bin' },
        { size: '100MB', file: 'test-100mb.bin' },
        { size: '500MB', file: 'test-500mb.bin' }
      ];
      
      const metrics = [];
      
      for (const test of sizes) {
        const startTime = Date.now();
        const result = await this.uploadFile(test.file);
        const duration = Date.now() - startTime;
        
        metrics.push({
          size: test.size,
          duration,
          throughput: this.calculateThroughput(test.size, duration),
          success: result.status === 200
        });
      }
      
      this.results.push({
        test: 'performance',
        metrics
      });
    }
  }
  ```
- [ ] Create assertion helpers
- [ ] Setup mock services
- [ ] Configure test scenarios

### Task 5: Implement Format Validators (AC: 4, 5)
- [ ] Create format-specific validators
  ```javascript
  // validators/file-validators.js
  class FileValidators {
    async validatePDF(buffer) {
      const header = buffer.slice(0, 5).toString();
      if (header !== '%PDF-') {
        throw new Error('Invalid PDF header');
      }
      
      // Check for JavaScript (potential security risk)
      if (buffer.includes('/JS') || buffer.includes('/JavaScript')) {
        throw new Error('PDF contains JavaScript');
      }
      
      // Validate structure
      const pdf = await pdfjsLib.getDocument(buffer).promise;
      
      return {
        valid: true,
        pages: pdf.numPages,
        info: await pdf.getMetadata()
      };
    }
    
    async validateCSV(buffer) {
      const text = buffer.toString();
      const lines = text.split('\n');
      
      if (lines.length === 0) {
        throw new Error('Empty CSV file');
      }
      
      const headers = lines[0].split(',');
      let rowCount = 0;
      let errors = [];
      
      for (let i = 1; i < lines.length; i++) {
        const row = lines[i].split(',');
        if (row.length !== headers.length) {
          errors.push(`Row ${i}: column count mismatch`);
        }
        rowCount++;
      }
      
      return {
        valid: errors.length === 0,
        headers,
        rowCount,
        errors
      };
    }
    
    async validateImage(buffer) {
      const metadata = await sharp(buffer).metadata();
      
      // Check for suspicious metadata
      if (metadata.exif) {
        const exifData = await exifReader(buffer);
        if (exifData.gps) {
          console.warn('Image contains GPS data');
        }
      }
      
      // Validate dimensions
      if (metadata.width > 10000 || metadata.height > 10000) {
        throw new Error('Image dimensions too large');
      }
      
      return {
        valid: true,
        format: metadata.format,
        width: metadata.width,
        height: metadata.height,
        hasAlpha: metadata.hasAlpha
      };
    }
  }
  ```
- [ ] Setup malware detection
- [ ] Configure size limits
- [ ] Create sanitizers

### Task 6: Test Large Files (AC: 6)
- [ ] Implement streaming upload
  ```javascript
  // streaming/large-file-handler.js
  class LargeFileHandler {
    async streamUpload(filePath, chunkSize = 5 * 1024 * 1024) {
      const stats = await fs.promises.stat(filePath);
      const fileSize = stats.size;
      const chunks = Math.ceil(fileSize / chunkSize);
      
      const uploadId = uuidv4();
      
      // Initialize multipart upload
      await this.initializeUpload(uploadId, path.basename(filePath));
      
      const stream = fs.createReadStream(filePath, {
        highWaterMark: chunkSize
      });
      
      let chunkNumber = 0;
      const etags = [];
      
      for await (const chunk of stream) {
        const etag = await this.uploadChunk(uploadId, chunk, chunkNumber);
        etags.push({ partNumber: chunkNumber + 1, etag });
        chunkNumber++;
        
        // Report progress
        this.reportProgress(uploadId, chunkNumber, chunks);
      }
      
      // Complete upload
      return await this.completeUpload(uploadId, etags);
    }
    
    async uploadChunk(uploadId, chunk, partNumber) {
      const response = await fetch(`${this.apiUrl}/upload/${uploadId}/part/${partNumber}`, {
        method: 'PUT',
        body: chunk,
        headers: {
          'Content-Length': chunk.length
        }
      });
      
      return response.headers.get('etag');
    }
    
    reportProgress(uploadId, current, total) {
      const percentage = (current / total * 100).toFixed(2);
      console.log(`Upload ${uploadId}: ${percentage}% (${current}/${total} chunks)`);
    }
  }
  ```
- [ ] Test resume capability
- [ ] Configure bandwidth limits
- [ ] Test timeout handling

### Task 7: Setup Performance Metrics (AC: 8)
- [ ] Create metrics collector
  ```javascript
  // metrics/file-metrics.js
  class FileMetricsCollector {
    constructor() {
      this.metrics = {
        uploads: [],
        processing: [],
        storage: [],
        errors: []
      };
    }
    
    recordUpload(file, duration, success) {
      this.metrics.uploads.push({
        timestamp: new Date(),
        filename: file.name,
        size: file.size,
        type: file.type,
        duration,
        success,
        throughput: (file.size / duration) * 1000 // bytes per second
      });
    }
    
    getStatistics() {
      const uploads = this.metrics.uploads;
      
      return {
        totalUploads: uploads.length,
        successRate: uploads.filter(u => u.success).length / uploads.length,
        averageDuration: uploads.reduce((sum, u) => sum + u.duration, 0) / uploads.length,
        averageThroughput: uploads.reduce((sum, u) => sum + u.throughput, 0) / uploads.length,
        
        byType: this.groupByType(uploads),
        bySizeRange: this.groupBySizeRange(uploads),
        
        percentiles: {
          p50: this.percentile(uploads.map(u => u.duration), 50),
          p95: this.percentile(uploads.map(u => u.duration), 95),
          p99: this.percentile(uploads.map(u => u.duration), 99)
        }
      };
    }
  }
  ```
- [ ] Create performance dashboard
- [ ] Setup alerting thresholds
- [ ] Generate performance reports

---

## Dev Notes

### Supported File Formats
```yaml
documents:
  - pdf: { maxSize: 100MB, features: [ocr, forms, signatures] }
  - docx: { maxSize: 50MB, features: [track-changes, comments] }
  - xlsx: { maxSize: 50MB, features: [formulas, macros] }

data:
  - csv: { maxSize: 500MB, features: [streaming, validation] }
  - json: { maxSize: 100MB, features: [schema-validation] }
  - xml: { maxSize: 100MB, features: [xsd-validation, xslt] }

images:
  - jpeg: { maxSize: 50MB, features: [exif, thumbnails] }
  - png: { maxSize: 50MB, features: [transparency, metadata] }
  - webp: { maxSize: 25MB, features: [animation] }

archives:
  - zip: { maxSize: 1GB, features: [password, streaming] }
  - tar: { maxSize: 1GB, features: [compression] }
```

### Performance Targets
- Small files (<1MB): < 500ms
- Medium files (1-10MB): < 2s
- Large files (10-100MB): < 10s
- Very large files (100MB-1GB): < 60s

### Testing Standards
- Test location: `/tests/file-processing/`
- Test all supported formats
- Include malicious files
- Test concurrent operations
- Verify cleanup after tests

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-09-22 | 1.0 | Initial story creation | Bob (SM) |

---

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent_

### Debug Log References
_To be populated during development_

### Completion Notes List
_To be populated during development_

### File List
_To be populated during development_

---

## QA Results
_To be populated by QA agent_