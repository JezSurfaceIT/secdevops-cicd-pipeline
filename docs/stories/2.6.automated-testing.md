# Story 2.6: Setup Automated Testing

**Epic:** 2 - CI/CD Pipeline Foundation  
**Story Number:** 2.6  
**Title:** Configure Comprehensive Automated Testing  
**Status:** READY  
**Points:** 5  
**Components:** Pipeline Testing Integration  

---

## Story

**As a** QA Engineer,  
**I want** automated testing integrated into the CI/CD pipeline,  
**so that** code quality is validated at every stage before deployment.

---

## Acceptance Criteria

1. Unit tests run on every commit
2. Integration tests run after successful builds
3. Code coverage minimum 80%
4. Performance tests for critical paths
5. Contract testing for APIs
6. Accessibility testing for UI
7. Test results published to dashboard
8. Failed tests block deployment
9. Parallel test execution for speed

---

## Tasks / Subtasks

### Task 1: Write Meta-Tests (TDD) (AC: 1, 2, 8)
- [ ] Create `testing/pipeline_test.go`
  - [ ] Test unit tests execute
  - [ ] Test integration tests run
  - [ ] Test coverage is calculated
  - [ ] Test failures stop pipeline
- [ ] Run tests to confirm they fail (Red phase)

### Task 2: Configure Unit Testing (AC: 1, 3)
- [ ] Setup test frameworks for each language
  ```groovy
  stage('Unit Tests') {
    parallel {
      stage('JavaScript') {
        steps {
          sh '''
            npm test -- --coverage --watchAll=false
            npx jest --coverage --coverageReporters=json --outputFile=coverage/jest.json
          '''
        }
      }
      stage('Go') {
        steps {
          sh '''
            go test -v -coverprofile=coverage.out ./...
            go tool cover -html=coverage.out -o coverage.html
          '''
        }
      }
      stage('Python') {
        steps {
          sh '''
            pytest --cov=app --cov-report=xml --cov-report=html
          '''
        }
      }
    }
  }
  ```
- [ ] Configure coverage thresholds
  ```javascript
  // jest.config.js
  module.exports = {
    coverageThreshold: {
      global: {
        branches: 80,
        functions: 80,
        lines: 80,
        statements: 80
      }
    },
    collectCoverageFrom: [
      'src/**/*.{js,jsx}',
      '!src/index.js',
      '!src/**/*.test.js'
    ]
  };
  ```
- [ ] Setup test data fixtures
- [ ] Configure test database

### Task 3: Implement Integration Testing (AC: 2)
- [ ] Create integration test suites
  ```javascript
  // tests/integration/api.test.js
  describe('API Integration Tests', () => {
    let server;
    let database;
    
    beforeAll(async () => {
      database = await setupTestDatabase();
      server = await startTestServer();
    });
    
    afterAll(async () => {
      await server.close();
      await database.disconnect();
    });
    
    test('GET /api/health returns 200', async () => {
      const response = await request(server)
        .get('/api/health')
        .expect(200);
      
      expect(response.body).toHaveProperty('status', 'healthy');
    });
    
    test('POST /api/users creates user', async () => {
      const userData = {
        email: 'test@example.com',
        name: 'Test User'
      };
      
      const response = await request(server)
        .post('/api/users')
        .send(userData)
        .expect(201);
      
      expect(response.body).toMatchObject(userData);
    });
  });
  ```
- [ ] Setup test containers
  ```groovy
  stage('Integration Tests') {
    steps {
      script {
        docker.image('postgres:13').withRun('-e POSTGRES_PASSWORD=test') { db ->
          docker.image('redis:6').withRun() { redis ->
            sh """
              export DATABASE_URL=postgresql://postgres:test@${db.id}:5432/test
              export REDIS_URL=redis://${redis.id}:6379
              npm run test:integration
            """
          }
        }
      }
    }
  }
  ```
- [ ] Configure service mocks
- [ ] Create test scenarios

### Task 4: Setup Performance Testing (AC: 4)
- [ ] Install performance testing tools
  ```bash
  npm install -g artillery
  pip install locust
  ```
- [ ] Create performance test scenarios
  ```yaml
  # performance/load-test.yml
  config:
    target: 'https://test.app.local'
    phases:
      - duration: 60
        arrivalRate: 10
        name: "Warm up"
      - duration: 120
        arrivalRate: 50
        name: "Load test"
      - duration: 60
        arrivalRate: 100
        name: "Stress test"
  scenarios:
    - name: "API Load Test"
      flow:
        - get:
            url: "/api/health"
        - think: 5
        - post:
            url: "/api/data"
            json:
              test: "data"
  ```
- [ ] Configure performance gates
  ```groovy
  stage('Performance Tests') {
    steps {
      sh '''
        artillery run performance/load-test.yml --output report.json
        artillery report report.json --output report.html
      '''
      
      script {
        def report = readJSON file: 'report.json'
        if (report.aggregate.latency.p99 > 2000) {
          error "P99 latency exceeds 2s threshold"
        }
      }
    }
  }
  ```
- [ ] Setup monitoring during tests
- [ ] Create performance baseline

### Task 5: Implement Contract Testing (AC: 5)
- [ ] Setup Pact for contract testing
  ```javascript
  // tests/contracts/consumer.pact.test.js
  const { Pact } = require('@pact-foundation/pact');
  const { API } = require('../src/api-client');
  
  describe('API Consumer Contract', () => {
    const provider = new Pact({
      consumer: 'Frontend',
      provider: 'Backend API',
      port: 1234,
      log: path.resolve(process.cwd(), 'logs', 'pact.log'),
      dir: path.resolve(process.cwd(), 'pacts')
    });
    
    beforeAll(() => provider.setup());
    afterAll(() => provider.finalize());
    
    describe('get user', () => {
      beforeAll(() => {
        return provider.addInteraction({
          state: 'user exists',
          uponReceiving: 'a request for user',
          withRequest: {
            method: 'GET',
            path: '/users/1'
          },
          willRespondWith: {
            status: 200,
            body: {
              id: 1,
              name: 'Test User',
              email: 'test@example.com'
            }
          }
        });
      });
      
      test('returns user data', async () => {
        const api = new API('http://localhost:1234');
        const user = await api.getUser(1);
        expect(user.name).toBe('Test User');
      });
    });
  });
  ```
- [ ] Configure provider verification
- [ ] Setup Pact Broker
- [ ] Create contract versioning

### Task 6: Configure Accessibility Testing (AC: 6)
- [ ] Install accessibility tools
  ```bash
  npm install --save-dev @axe-core/playwright
  npm install --save-dev pa11y
  ```
- [ ] Create accessibility tests
  ```javascript
  // tests/accessibility/a11y.test.js
  const { injectAxe, checkA11y } = require('axe-playwright');
  
  describe('Accessibility Tests', () => {
    test('Home page is accessible', async () => {
      await page.goto('/');
      await injectAxe(page);
      const results = await checkA11y(page, null, {
        detailedReport: true,
        detailedReportOptions: {
          html: true
        }
      });
      
      expect(results.violations).toHaveLength(0);
    });
  });
  ```
- [ ] Configure accessibility standards
  ```javascript
  // pa11y.config.js
  module.exports = {
    standard: 'WCAG2AA',
    timeout: 30000,
    wait: 1000,
    chromeLaunchConfig: {
      args: ['--no-sandbox']
    },
    actions: [
      'wait for element #app to be visible'
    ]
  };
  ```
- [ ] Create accessibility reports
- [ ] Setup automated fixes

### Task 7: Setup Test Reporting (AC: 7)
- [ ] Configure test result aggregation
  ```groovy
  post {
    always {
      junit '**/test-results/*.xml'
      
      publishHTML target: [
        reportName: 'Coverage Report',
        reportDir: 'coverage',
        reportFiles: 'index.html'
      ]
      
      publishHTML target: [
        reportName: 'Performance Report',
        reportDir: 'performance',
        reportFiles: 'report.html'
      ]
      
      script {
        def testResults = [
          unit: readJSON(file: 'test-results/unit.json'),
          integration: readJSON(file: 'test-results/integration.json'),
          performance: readJSON(file: 'test-results/performance.json')
        ]
        
        sendTestResultsToDashboard(testResults)
      }
    }
  }
  ```
- [ ] Create test dashboard
- [ ] Setup trend analysis
- [ ] Configure notifications

### Task 8: Enable Parallel Execution (AC: 9)
- [ ] Configure test splitting
  ```groovy
  stage('Parallel Tests') {
    parallel {
      stage('Test Suite 1') {
        steps {
          sh 'npm test -- --shard=1/3'
        }
      }
      stage('Test Suite 2') {
        steps {
          sh 'npm test -- --shard=2/3'
        }
      }
      stage('Test Suite 3') {
        steps {
          sh 'npm test -- --shard=3/3'
        }
      }
    }
  }
  ```
- [ ] Setup distributed testing
- [ ] Configure test balancing
- [ ] Optimize test execution time

---

## Dev Notes

### Complete Test Pipeline
```groovy
pipeline {
  agent any
  
  stages {
    stage('Test') {
      parallel {
        stage('Unit') {
          steps {
            sh 'make test-unit'
          }
          post {
            always {
              junit 'reports/unit/*.xml'
              publishCoverage adapters: [coberturaAdapter('coverage.xml')]
            }
          }
        }
        
        stage('Integration') {
          steps {
            sh 'make test-integration'
          }
        }
        
        stage('Contract') {
          steps {
            sh 'make test-contracts'
          }
        }
        
        stage('Performance') {
          steps {
            sh 'make test-performance'
          }
        }
        
        stage('Accessibility') {
          steps {
            sh 'make test-accessibility'
          }
        }
      }
    }
    
    stage('Quality Gate') {
      steps {
        script {
          def coverage = readJSON file: 'coverage.json'
          if (coverage.total.percentage < 80) {
            error "Coverage ${coverage.total.percentage}% is below 80%"
          }
        }
      }
    }
  }
}
```

### Test Configuration Matrix
```yaml
test_matrix:
  environments:
    - node: ['14', '16', '18']
    - python: ['3.8', '3.9', '3.10']
    - database: ['postgres:12', 'postgres:13', 'postgres:14']
  
  browsers:
    - chrome: latest
    - firefox: latest
    - safari: latest
    - edge: latest
```

### Testing Standards
- Test location: `/tests/`
- Naming convention: `*.test.js`, `*_test.go`, `test_*.py`
- Mock external services
- Use test databases
- Clean up after tests

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-09-22 | 1.0 | Initial story creation | Bob (SM) |

---

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent_

### Debug Log References
_To be populated during development_

### Completion Notes List
_To be populated during development_

### File List
_To be populated during development_

---

## QA Results
_To be populated by QA agent_