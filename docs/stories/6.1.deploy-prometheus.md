# Story 6.1: Deploy Prometheus

**Epic:** 6 - Monitoring & Observability  
**Story Number:** 6.1  
**Title:** Setup Prometheus for Metrics Collection  
**Status:** READY  
**Points:** 5  
**Component:** 1001 (Prometheus)  

---

## Story

**As a** Site Reliability Engineer,  
**I want** Prometheus deployed for comprehensive metrics collection,  
**so that** we have real-time visibility into system performance and health.

---

## Acceptance Criteria

1. Prometheus deployed with high availability (2+ instances)
2. Service discovery configured for all components
3. Metrics scraped from all applications and infrastructure
4. 15-day retention for local storage
5. Remote write to long-term storage configured
6. Recording rules for performance optimization
7. Federation setup for multi-region metrics
8. Secure access with authentication

---

## Tasks / Subtasks

### Task 1: Write Monitoring Tests (TDD) (AC: 1, 3, 5)
- [ ] Create `monitoring/prometheus_test.go`
  - [ ] Test Prometheus deployment
  - [ ] Test service discovery works
  - [ ] Test metrics collection
  - [ ] Test remote storage write
- [ ] Run tests to confirm they fail (Red phase)

### Task 2: Deploy Prometheus Infrastructure (AC: 1, 5)
- [ ] Create Prometheus deployment
  ```yaml
  # kubernetes/prometheus-deployment.yaml
  apiVersion: v1
  kind: ConfigMap
  metadata:
    name: prometheus-config
    namespace: monitoring
  data:
    prometheus.yml: |
      global:
        scrape_interval: 30s
        evaluation_interval: 30s
        external_labels:
          cluster: 'prod-eastus'
          environment: 'production'
      
      # Remote write for long-term storage
      remote_write:
        - url: "https://thanos-receiver.monitoring.svc.cluster.local:19291/api/v1/receive"
          tls_config:
            insecure_skip_verify: false
          queue_config:
            capacity: 10000
            max_shards: 200
            min_shards: 1
            max_samples_per_send: 5000
            batch_send_deadline: 5s
            min_backoff: 30ms
            max_backoff: 100ms
      
      # Alertmanager configuration
      alerting:
        alertmanagers:
          - static_configs:
              - targets: ['alertmanager:9093']
      
      # Rules files
      rule_files:
        - '/etc/prometheus/rules/*.yml'
      
      # Service discovery configurations
      scrape_configs:
        - job_name: 'kubernetes-apiservers'
          kubernetes_sd_configs:
            - role: endpoints
          scheme: https
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
          relabel_configs:
            - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
              action: keep
              regex: default;kubernetes;https
        
        - job_name: 'kubernetes-nodes'
          kubernetes_sd_configs:
            - role: node
          scheme: https
          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
          relabel_configs:
            - action: labelmap
              regex: __meta_kubernetes_node_label_(.+)
        
        - job_name: 'kubernetes-pods'
          kubernetes_sd_configs:
            - role: pod
          relabel_configs:
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
              action: keep
              regex: true
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
              action: replace
              target_label: __metrics_path__
              regex: (.+)
            - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
              action: replace
              regex: ([^:]+)(?::\d+)?;(\d+)
              replacement: $1:$2
              target_label: __address__
        
        - job_name: 'azure-metrics'
          azure_sd_configs:
            - subscription_id: "${AZURE_SUBSCRIPTION_ID}"
              tenant_id: "${AZURE_TENANT_ID}"
              client_id: "${AZURE_CLIENT_ID}"
              client_secret: "${AZURE_CLIENT_SECRET}"
              refresh_interval: 300s
              port: 9100
          relabel_configs:
            - source_labels: [__meta_azure_machine_name]
              target_label: instance
            - source_labels: [__meta_azure_machine_location]
              target_label: location
  ---
  apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    name: prometheus
    namespace: monitoring
  spec:
    replicas: 2
    serviceName: prometheus-headless
    selector:
      matchLabels:
        app: prometheus
    template:
      metadata:
        labels:
          app: prometheus
      spec:
        serviceAccountName: prometheus
        containers:
        - name: prometheus
          image: prom/prometheus:v2.45.0
          args:
            - '--config.file=/etc/prometheus/prometheus.yml'
            - '--storage.tsdb.path=/prometheus'
            - '--storage.tsdb.retention.time=15d'
            - '--storage.tsdb.retention.size=50GB'
            - '--web.enable-lifecycle'
            - '--web.enable-admin-api'
          ports:
          - containerPort: 9090
            name: web
          resources:
            requests:
              memory: "2Gi"
              cpu: "1"
            limits:
              memory: "4Gi"
              cpu: "2"
          volumeMounts:
          - name: config
            mountPath: /etc/prometheus
          - name: storage
            mountPath: /prometheus
          - name: rules
            mountPath: /etc/prometheus/rules
        volumes:
        - name: config
          configMap:
            name: prometheus-config
        - name: rules
          configMap:
            name: prometheus-rules
    volumeClaimTemplates:
    - metadata:
        name: storage
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: managed-premium
        resources:
          requests:
            storage: 100Gi
  ```
- [ ] Deploy using Helm
  ```bash
  # Install Prometheus using Helm
  helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
  helm repo update
  
  helm install prometheus prometheus-community/kube-prometheus-stack \
    --namespace monitoring \
    --create-namespace \
    --values prometheus-values.yaml
  ```
- [ ] Configure persistent storage
- [ ] Setup backup strategy

### Task 3: Configure Service Discovery (AC: 2, 3)
- [ ] Setup Azure service discovery
  ```yaml
  # azure-sd-config.yaml
  - job_name: 'azure-vms'
    azure_sd_configs:
      - subscription_id: "${AZURE_SUBSCRIPTION_ID}"
        tenant_id: "${AZURE_TENANT_ID}"
        client_id: "${AZURE_CLIENT_ID}"
        client_secret: "${AZURE_CLIENT_SECRET}"
        refresh_interval: 300s
        port: 9100
        resource_group: "rg-oversight-prod-saas-eastus"
    relabel_configs:
      - source_labels: [__meta_azure_machine_name]
        target_label: instance
      - source_labels: [__meta_azure_machine_resource_group]
        target_label: resource_group
      - source_labels: [__meta_azure_machine_tag_environment]
        target_label: environment
  
  - job_name: 'azure-sql'
    static_configs:
      - targets: ['psql-oversight-prod.postgres.database.azure.com:9187']
    metrics_path: /metrics
    params:
      target: ['psql-oversight-prod.postgres.database.azure.com:5432']
  
  - job_name: 'azure-redis'
    static_configs:
      - targets: ['redis-oversight-prod.redis.cache.windows.net:9121']
  ```
- [ ] Configure application metrics
  ```javascript
  // metrics/prometheus-exporter.js
  const promClient = require('prom-client');
  const express = require('express');
  
  class MetricsExporter {
    constructor() {
      this.register = new promClient.Registry();
      promClient.collectDefaultMetrics({ register: this.register });
      
      // Custom metrics
      this.httpDuration = new promClient.Histogram({
        name: 'http_request_duration_seconds',
        help: 'Duration of HTTP requests in seconds',
        labelNames: ['method', 'route', 'status_code'],
        buckets: [0.1, 0.3, 0.5, 0.7, 1, 3, 5, 7, 10]
      });
      
      this.dbQueryDuration = new promClient.Histogram({
        name: 'db_query_duration_seconds',
        help: 'Duration of database queries in seconds',
        labelNames: ['operation', 'table'],
        buckets: [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1]
      });
      
      this.cacheHits = new promClient.Counter({
        name: 'cache_hits_total',
        help: 'Total number of cache hits',
        labelNames: ['cache_name']
      });
      
      this.cacheMisses = new promClient.Counter({
        name: 'cache_misses_total',
        help: 'Total number of cache misses',
        labelNames: ['cache_name']
      });
      
      this.businessMetrics = new promClient.Gauge({
        name: 'business_metric',
        help: 'Business metrics',
        labelNames: ['metric_name']
      });
      
      this.register.registerMetric(this.httpDuration);
      this.register.registerMetric(this.dbQueryDuration);
      this.register.registerMetric(this.cacheHits);
      this.register.registerMetric(this.cacheMisses);
      this.register.registerMetric(this.businessMetrics);
    }
    
    middleware() {
      return (req, res, next) => {
        const start = Date.now();
        
        res.on('finish', () => {
          const duration = (Date.now() - start) / 1000;
          this.httpDuration
            .labels(req.method, req.route?.path || req.url, res.statusCode)
            .observe(duration);
        });
        
        next();
      };
    }
    
    async getMetrics() {
      return await this.register.metrics();
    }
    
    setupEndpoint(app) {
      app.get('/metrics', async (req, res) => {
        res.set('Content-Type', this.register.contentType);
        res.send(await this.getMetrics());
      });
    }
  }
  
  module.exports = new MetricsExporter();
  ```
- [ ] Test service discovery
- [ ] Validate all targets scraped

### Task 4: Setup Remote Storage (AC: 5)
- [ ] Deploy Thanos for long-term storage
  ```yaml
  # thanos-receiver.yaml
  apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    name: thanos-receiver
    namespace: monitoring
  spec:
    replicas: 3
    serviceName: thanos-receiver-headless
    selector:
      matchLabels:
        app: thanos-receiver
    template:
      metadata:
        labels:
          app: thanos-receiver
      spec:
        containers:
        - name: thanos-receiver
          image: quay.io/thanos/thanos:v0.32.0
          args:
            - receive
            - --grpc-address=0.0.0.0:10901
            - --http-address=0.0.0.0:10902
            - --remote-write.address=0.0.0.0:19291
            - --objstore.config-file=/etc/thanos/objstore.yml
            - --tsdb.path=/var/thanos/receive
            - --tsdb.retention=7d
            - --label=receive_replica="$(POD_NAME)"
            - --label=receive="true"
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
          ports:
          - containerPort: 10901
            name: grpc
          - containerPort: 10902
            name: http
          - containerPort: 19291
            name: remote-write
          volumeMounts:
          - name: objstore-config
            mountPath: /etc/thanos
          - name: data
            mountPath: /var/thanos/receive
        volumes:
        - name: objstore-config
          secret:
            secretName: thanos-objstore-config
    volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 100Gi
  ```
- [ ] Configure Azure Blob for Thanos
  ```yaml
  # thanos-objstore.yml
  type: AZURE
  config:
    storage_account: "${AZURE_STORAGE_ACCOUNT}"
    storage_account_key: "${AZURE_STORAGE_KEY}"
    container: "thanos-metrics"
    endpoint: "blob.core.windows.net"
    max_retries: 3
  ```
- [ ] Test remote write
- [ ] Verify data in object storage

### Task 5: Create Recording Rules (AC: 6)
- [ ] Define recording rules
  ```yaml
  # recording-rules.yml
  groups:
    - name: performance_rules
      interval: 30s
      rules:
        # Request rate
        - record: instance:node_cpu:rate5m
          expr: |
            100 - (avg by (instance) (
              rate(node_cpu_seconds_total{mode="idle"}[5m])
            ) * 100)
        
        # Memory usage
        - record: instance:node_memory_usage:percentage
          expr: |
            100 - (
              node_memory_MemAvailable_bytes / 
              node_memory_MemTotal_bytes * 100
            )
        
        # HTTP request rate
        - record: job:http_requests:rate5m
          expr: |
            sum by (job, method, status) (
              rate(http_requests_total[5m])
            )
        
        # Error rate
        - record: job:http_errors:rate5m
          expr: |
            sum by (job) (
              rate(http_requests_total{status=~"5.."}[5m])
            )
        
        # P95 latency
        - record: job:http_request_duration:p95_5m
          expr: |
            histogram_quantile(0.95,
              sum by (job, le) (
                rate(http_request_duration_seconds_bucket[5m])
              )
            )
        
        # Database connection pool usage
        - record: instance:db_connections:usage
          expr: |
            (pg_stat_database_numbackends / 
             pg_settings_max_connections) * 100
    
    - name: business_rules
      interval: 60s
      rules:
        # Active users
        - record: business:active_users:count
          expr: |
            count(
              increase(user_activity_total[1h]) > 0
            )
        
        # Transaction rate
        - record: business:transactions:rate1h
          expr: |
            sum(rate(business_transaction_total[1h]))
        
        # Revenue per minute
        - record: business:revenue:rate1m
          expr: |
            sum(rate(business_revenue_total[1m]))
  ```
- [ ] Optimize query performance
- [ ] Test rule evaluation
- [ ] Monitor rule performance

### Task 6: Setup Federation (AC: 7)
- [ ] Configure federation endpoint
  ```yaml
  # federation-config.yaml
  - job_name: 'federate'
    scrape_interval: 30s
    honor_labels: true
    metrics_path: '/federate'
    params:
      'match[]':
        - '{job=~"kubernetes-.*"}'
        - '{__name__=~"job:.*"}'
        - '{__name__=~"instance:.*"}'
    static_configs:
      - targets:
        - 'prometheus-westus.monitoring.svc:9090'
        - 'prometheus-northeurope.monitoring.svc:9090'
  ```
- [ ] Setup cross-region queries
- [ ] Test federation
- [ ] Configure global view

### Task 7: Implement Security (AC: 8)
- [ ] Configure authentication
  ```yaml
  # prometheus-auth.yaml
  apiVersion: v1
  kind: ConfigMap
  metadata:
    name: prometheus-auth
  data:
    web-config.yml: |
      tls_server_config:
        cert_file: /etc/prometheus/certs/tls.crt
        key_file: /etc/prometheus/certs/tls.key
      basic_auth_users:
        admin: $2a$10$XvWVfIJHgHR0eQVnZvLkHuHQh0MvNtZNL8t8eXrHq8TaF3Y4xJj3m  # bcrypt hash
  ```
- [ ] Setup OAuth2 proxy
  ```yaml
  # oauth2-proxy.yaml
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: oauth2-proxy
    namespace: monitoring
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: oauth2-proxy
    template:
      metadata:
        labels:
          app: oauth2-proxy
      spec:
        containers:
        - name: oauth2-proxy
          image: quay.io/oauth2-proxy/oauth2-proxy:v7.4.0
          args:
            - --provider=azure
            - --azure-tenant=${AZURE_TENANT_ID}
            - --client-id=${OAUTH_CLIENT_ID}
            - --client-secret=${OAUTH_CLIENT_SECRET}
            - --upstream=http://prometheus:9090
            - --http-address=0.0.0.0:4180
            - --cookie-secure=true
            - --cookie-secret=${COOKIE_SECRET}
            - --email-domain=oversight.com
          ports:
          - containerPort: 4180
            name: http
  ```
- [ ] Configure network policies
- [ ] Test authentication

### Task 8: Setup Monitoring Dashboard (AC: 1)
- [ ] Create Prometheus self-monitoring
  ```yaml
  # prometheus-self-monitoring.yml
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
    metrics_path: '/metrics'
  ```
- [ ] Create health checks
- [ ] Setup alerting for Prometheus
- [ ] Document access procedures

---

## Dev Notes

### Prometheus Endpoints
```
Internal: http://prometheus.monitoring.svc.cluster.local:9090
External: https://prometheus.oversight.com (through OAuth2 proxy)
Federation: http://prometheus.monitoring.svc.cluster.local:9090/federate
Remote Write: http://thanos-receiver:19291/api/v1/receive
```

### Metric Naming Conventions
```
Format: {namespace}_{subsystem}_{name}_{unit}
Examples:
- http_requests_total
- http_request_duration_seconds
- db_connections_active
- cache_hits_total
- business_transactions_total
```

### Testing Standards
- Test location: `/tests/monitoring/prometheus/`
- Validate all targets are scraped
- Test recording rules evaluate correctly
- Verify remote storage works
- Check federation endpoints

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-09-22 | 1.0 | Initial story creation | Bob (SM) |

---

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent_

### Debug Log References
_To be populated during development_

### Completion Notes List
_To be populated during development_

### File List
_To be populated during development_

---

## QA Results
_To be populated by QA agent_