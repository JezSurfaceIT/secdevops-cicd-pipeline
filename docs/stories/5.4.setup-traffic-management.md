# Story 5.4: Setup Traffic Management

**Epic:** 5 - CBE Distribution  
**Story Number:** 5.4  
**Title:** Implement Global Load Balancing and Traffic Shaping  
**Status:** READY  
**Points:** 3  
**Component:** 534 (Traffic Management)  

---

## Story

**As a** Network Engineer,  
**I want** intelligent global traffic management,  
**so that** traffic is optimally routed based on performance, cost, and availability.

---

## Acceptance Criteria

1. Global load balancing with < 100ms decision time
2. Traffic shaping based on service tiers
3. Automatic traffic shifting during incidents
4. Cost-optimized routing for different regions
5. Quality of Service (QoS) guarantees enforced
6. Traffic analytics with real-time visibility
7. Rate limiting per customer tier
8. Canary deployments with traffic splitting

---

## Tasks / Subtasks

### Task 1: Write Traffic Management Tests (TDD) (AC: 1, 3, 8)
- [ ] Create `distribution/traffic_test.go`
  - [ ] Test load balancing algorithms
  - [ ] Test traffic shifting
  - [ ] Test rate limiting
  - [ ] Test canary routing
- [ ] Run tests to confirm they fail (Red phase)

### Task 2: Deploy Global Load Balancer (AC: 1, 3)
- [ ] Configure Azure Front Door load balancing
  ```hcl
  resource "azurerm_cdn_frontdoor_origin_group" "global_lb" {
    name                     = "global-load-balancer"
    cdn_frontdoor_profile_id = azurerm_cdn_frontdoor_profile.main.id
    
    session_affinity_enabled = true
    
    restore_traffic_time_to_healed_or_new_endpoint_in_minutes = 5
    
    health_probe {
      interval_in_seconds = 10
      path               = "/health/detailed"
      protocol           = "Https"
      probe_method       = "GET"
    }
    
    load_balancing {
      additional_latency_in_milliseconds = 50
      sample_size                        = 4
      successful_samples_required        = 2
    }
  }
  
  resource "azurerm_cdn_frontdoor_rule_set" "traffic_rules" {
    name                     = "traffic-management-rules"
    cdn_frontdoor_profile_id = azurerm_cdn_frontdoor_profile.main.id
  }
  
  resource "azurerm_cdn_frontdoor_rule" "load_balancing" {
    name                      = "intelligent-routing"
    cdn_frontdoor_rule_set_id = azurerm_cdn_frontdoor_rule_set.traffic_rules.id
    order                     = 1
    
    conditions {
      request_header_condition {
        header_name  = "X-Priority"
        operator     = "Equal"
        match_values = ["high"]
      }
    }
    
    actions {
      route_configuration_override_action {
        cdn_frontdoor_origin_group_id = azurerm_cdn_frontdoor_origin_group.premium.id
        forwarding_protocol           = "HttpsOnly"
        cache_behavior               = "HonorOrigin"
      }
    }
  }
  ```
- [ ] Implement custom load balancing
  ```javascript
  // services/load-balancer.js
  class GlobalLoadBalancer {
    constructor() {
      this.algorithms = {
        roundRobin: new RoundRobinAlgorithm(),
        leastConnections: new LeastConnectionsAlgorithm(),
        weightedResponse: new WeightedResponseTimeAlgorithm(),
        geographic: new GeographicAlgorithm(),
        costOptimized: new CostOptimizedAlgorithm()
      };
      
      this.endpoints = new Map();
      this.metrics = new Map();
    }
    
    async route(request) {
      const startTime = Date.now();
      
      // Get healthy endpoints
      const available = await this.getHealthyEndpoints();
      
      if (available.length === 0) {
        throw new Error('No healthy endpoints available');
      }
      
      // Select algorithm based on request context
      const algorithm = this.selectAlgorithm(request);
      
      // Calculate endpoint scores
      const scores = await this.calculateScores(available, request, algorithm);
      
      // Select best endpoint
      const selected = this.selectEndpoint(scores);
      
      // Update metrics
      this.updateMetrics(selected, {
        requestId: request.id,
        algorithm: algorithm.name,
        decisionTime: Date.now() - startTime,
        scores
      });
      
      // Apply traffic shaping if needed
      await this.applyTrafficShaping(request, selected);
      
      return selected;
    }
    
    selectAlgorithm(request) {
      // Priority traffic gets performance-based routing
      if (request.headers['x-priority'] === 'high') {
        return this.algorithms.weightedResponse;
      }
      
      // Cost-sensitive traffic
      if (request.headers['x-tier'] === 'free') {
        return this.algorithms.costOptimized;
      }
      
      // Geographic preference
      if (request.headers['x-geo-preference']) {
        return this.algorithms.geographic;
      }
      
      // Default to least connections
      return this.algorithms.leastConnections;
    }
    
    async calculateScores(endpoints, request, algorithm) {
      const scores = await Promise.all(
        endpoints.map(async endpoint => {
          const baseScore = await algorithm.score(endpoint, request);
          
          // Apply modifiers
          const modifiers = {
            health: await this.getHealthScore(endpoint),
            capacity: await this.getCapacityScore(endpoint),
            cost: this.getCostScore(endpoint, request),
            latency: await this.getLatencyScore(endpoint, request),
            affinity: this.getAffinityScore(endpoint, request)
          };
          
          // Weighted final score
          const finalScore = 
            baseScore * 0.4 +
            modifiers.health * 0.2 +
            modifiers.capacity * 0.15 +
            modifiers.cost * 0.1 +
            modifiers.latency * 0.1 +
            modifiers.affinity * 0.05;
          
          return {
            endpoint,
            baseScore,
            modifiers,
            finalScore
          };
        })
      );
      
      return scores.sort((a, b) => b.finalScore - a.finalScore);
    }
    
    async getHealthScore(endpoint) {
      const health = await this.healthChecker.check(endpoint);
      
      // Consider recent health history
      const history = this.metrics.get(endpoint.id)?.healthHistory || [];
      const recentFailures = history.filter(h => !h.healthy && 
        Date.now() - h.timestamp < 300000).length;
      
      // Degrade score based on recent failures
      const historyScore = Math.max(0, 1 - (recentFailures * 0.2));
      
      return health.healthy ? historyScore : 0;
    }
    
    async getCapacityScore(endpoint) {
      const metrics = await this.metricsCollector.get(endpoint);
      
      // CPU and memory utilization
      const cpuScore = Math.max(0, 1 - (metrics.cpu / 100));
      const memoryScore = Math.max(0, 1 - (metrics.memory / 100));
      
      // Connection pool availability
      const connectionScore = metrics.availableConnections / metrics.maxConnections;
      
      return (cpuScore + memoryScore + connectionScore) / 3;
    }
    
    getCostScore(endpoint, request) {
      const originCost = this.getCostPerRequest(endpoint, request);
      const maxCost = 0.10; // 10 cents per request max
      
      return Math.max(0, 1 - (originCost / maxCost));
    }
  }
  ```
- [ ] Configure health checks
- [ ] Test failover scenarios

### Task 3: Implement Traffic Shaping (AC: 2, 5)
- [ ] Configure QoS policies
  ```javascript
  // services/traffic-shaper.js
  class TrafficShaper {
    constructor() {
      this.policies = {
        premium: {
          bandwidth: Infinity,
          priority: 1,
          latencyTarget: 50,
          burstAllowance: 2.0
        },
        standard: {
          bandwidth: 100 * 1024 * 1024, // 100 Mbps
          priority: 2,
          latencyTarget: 100,
          burstAllowance: 1.5
        },
        free: {
          bandwidth: 10 * 1024 * 1024, // 10 Mbps
          priority: 3,
          latencyTarget: 200,
          burstAllowance: 1.0
        }
      };
      
      this.queues = new Map();
      this.tokens = new Map();
    }
    
    async shapeTraffic(request, tier) {
      const policy = this.policies[tier];
      const queue = this.getQueue(tier);
      
      // Check bandwidth limit
      if (!this.checkBandwidth(tier, request.size)) {
        await this.throttle(request, tier);
      }
      
      // Priority queueing
      queue.add({
        request,
        priority: policy.priority,
        timestamp: Date.now()
      });
      
      // Process queue based on priority
      return await this.processQueue(tier);
    }
    
    checkBandwidth(tier, size) {
      const policy = this.policies[tier];
      const bucket = this.getTokenBucket(tier);
      
      // Token bucket algorithm
      const now = Date.now();
      const elapsed = now - bucket.lastRefill;
      const refillAmount = (elapsed / 1000) * policy.bandwidth;
      
      bucket.tokens = Math.min(
        bucket.capacity,
        bucket.tokens + refillAmount
      );
      bucket.lastRefill = now;
      
      if (bucket.tokens >= size) {
        bucket.tokens -= size;
        return true;
      }
      
      // Check burst allowance
      if (bucket.tokens * policy.burstAllowance >= size) {
        bucket.tokens = 0;
        return true;
      }
      
      return false;
    }
    
    async throttle(request, tier) {
      const policy = this.policies[tier];
      const delay = this.calculateDelay(request.size, policy.bandwidth);
      
      console.log(`Throttling ${tier} request for ${delay}ms`);
      
      await new Promise(resolve => setTimeout(resolve, delay));
    }
    
    getTokenBucket(tier) {
      if (!this.tokens.has(tier)) {
        const policy = this.policies[tier];
        this.tokens.set(tier, {
          tokens: policy.bandwidth,
          capacity: policy.bandwidth * policy.burstAllowance,
          lastRefill: Date.now()
        });
      }
      return this.tokens.get(tier);
    }
    
    async enforceQoS(request, response) {
      const tier = request.headers['x-tier'] || 'free';
      const policy = this.policies[tier];
      
      // Set QoS headers
      response.headers.set('X-QoS-Tier', tier);
      response.headers.set('X-QoS-Priority', policy.priority);
      
      // Check if we met latency target
      const latency = Date.now() - request.startTime;
      if (latency > policy.latencyTarget) {
        response.headers.set('X-QoS-Violation', 'latency');
        
        // Log SLA violation
        await this.logViolation({
          tier,
          type: 'latency',
          target: policy.latencyTarget,
          actual: latency,
          request: request.id
        });
      }
      
      return response;
    }
  }
  ```
- [ ] Implement bandwidth limiting
- [ ] Configure priority queues
- [ ] Test QoS enforcement

### Task 4: Setup Automatic Traffic Shifting (AC: 3)
- [ ] Create incident response system
  ```javascript
  // services/traffic-shifter.js
  class TrafficShifter {
    constructor() {
      this.shifts = new Map();
      this.incidents = new Map();
    }
    
    async handleIncident(incident) {
      console.log(`Handling incident: ${incident.type} on ${incident.endpoint}`);
      
      const shift = {
        id: this.generateId(),
        incident: incident.id,
        startTime: Date.now(),
        originalWeights: await this.getCurrentWeights(),
        status: 'shifting'
      };
      
      this.shifts.set(shift.id, shift);
      
      try {
        // Determine shift strategy
        const strategy = this.selectStrategy(incident);
        
        // Calculate new weights
        const newWeights = await strategy.calculate(incident);
        
        // Gradually shift traffic
        await this.gradualShift(shift.originalWeights, newWeights);
        
        shift.newWeights = newWeights;
        shift.status = 'active';
        
        // Monitor shifted traffic
        this.monitorShift(shift);
        
        return shift;
      } catch (error) {
        shift.status = 'failed';
        shift.error = error.message;
        throw error;
      }
    }
    
    async gradualShift(currentWeights, targetWeights, duration = 60000) {
      const steps = 10;
      const stepDuration = duration / steps;
      
      for (let i = 1; i <= steps; i++) {
        const progress = i / steps;
        const intermediateWeights = {};
        
        for (const endpoint in targetWeights) {
          const current = currentWeights[endpoint] || 0;
          const target = targetWeights[endpoint];
          intermediateWeights[endpoint] = current + (target - current) * progress;
        }
        
        await this.updateWeights(intermediateWeights);
        
        // Check health during shift
        const health = await this.checkHealth();
        if (!health.healthy) {
          console.log('Health check failed during shift, rolling back');
          await this.updateWeights(currentWeights);
          throw new Error('Traffic shift aborted due to health check failure');
        }
        
        await new Promise(resolve => setTimeout(resolve, stepDuration));
      }
    }
    
    selectStrategy(incident) {
      const strategies = {
        'endpoint-failure': {
          calculate: async (incident) => {
            // Remove failed endpoint
            const weights = await this.getCurrentWeights();
            delete weights[incident.endpoint];
            
            // Redistribute weight
            const failedWeight = incident.originalWeight;
            const remaining = Object.keys(weights);
            const additional = failedWeight / remaining.length;
            
            remaining.forEach(endpoint => {
              weights[endpoint] += additional;
            });
            
            return weights;
          }
        },
        
        'high-latency': {
          calculate: async (incident) => {
            // Reduce weight of slow endpoint
            const weights = await this.getCurrentWeights();
            weights[incident.endpoint] *= 0.3;
            
            // Redistribute to faster endpoints
            const metrics = await this.getLatencyMetrics();
            const fast = metrics.filter(m => m.latency < 100);
            
            const redistributed = weights[incident.endpoint] * 0.7;
            fast.forEach(endpoint => {
              weights[endpoint.id] += redistributed / fast.length;
            });
            
            return weights;
          }
        },
        
        'capacity': {
          calculate: async (incident) => {
            // Shift based on available capacity
            const capacities = await this.getCapacities();
            const totalCapacity = capacities.reduce((sum, c) => sum + c.available, 0);
            
            const weights = {};
            capacities.forEach(c => {
              weights[c.endpoint] = c.available / totalCapacity;
            });
            
            return weights;
          }
        }
      };
      
      return strategies[incident.type] || strategies['endpoint-failure'];
    }
    
    async autoRecover(shift) {
      console.log(`Starting auto-recovery for shift ${shift.id}`);
      
      // Monitor original endpoint
      const checkInterval = setInterval(async () => {
        const health = await this.checkEndpointHealth(shift.incident.endpoint);
        
        if (health.healthy) {
          console.log('Endpoint recovered, shifting traffic back');
          
          clearInterval(checkInterval);
          
          // Gradually restore original weights
          await this.gradualShift(
            await this.getCurrentWeights(),
            shift.originalWeights,
            120000 // 2 minutes for recovery
          );
          
          shift.status = 'recovered';
          shift.recoveredAt = Date.now();
        }
      }, 30000); // Check every 30 seconds
    }
  }
  ```
- [ ] Configure automatic recovery
- [ ] Setup shift monitoring
- [ ] Test shift scenarios

### Task 5: Implement Cost-Optimized Routing (AC: 4)
- [ ] Create cost calculation service
  ```javascript
  // services/cost-optimizer.js
  class CostOptimizedRouter {
    constructor() {
      this.costs = {
        bandwidth: {
          'same-region': 0.00,
          'same-continent': 0.02,
          'cross-continent': 0.08
        },
        compute: {
          'eastus': 0.10,
          'westeurope': 0.12,
          'southeastasia': 0.08
        },
        cdn: {
          'standard': 0.04,
          'premium': 0.08
        }
      };
    }
    
    async routeWithCostOptimization(request) {
      const options = await this.getRoutingOptions(request);
      
      // Calculate cost for each option
      const costed = await Promise.all(
        options.map(async option => ({
          ...option,
          cost: await this.calculateCost(request, option),
          performance: await this.estimatePerformance(request, option)
        }))
      );
      
      // Find optimal based on tier
      const tier = request.headers['x-tier'] || 'standard';
      return this.selectOptimal(costed, tier);
    }
    
    async calculateCost(request, option) {
      const components = {
        bandwidth: this.calculateBandwidthCost(request, option),
        compute: this.calculateComputeCost(request, option),
        cdn: this.calculateCDNCost(request, option),
        storage: this.calculateStorageCost(request, option)
      };
      
      const total = Object.values(components).reduce((sum, cost) => sum + cost, 0);
      
      return {
        total,
        components,
        perGB: total / (request.estimatedSize / 1024 / 1024 / 1024)
      };
    }
    
    calculateBandwidthCost(request, option) {
      const source = request.clientRegion;
      const destination = option.region;
      
      let costType = 'same-region';
      if (source !== destination) {
        const sourceCont = this.getContinent(source);
        const destCont = this.getContinent(destination);
        costType = sourceCont === destCont ? 'same-continent' : 'cross-continent';
      }
      
      const gbTransferred = request.estimatedSize / 1024 / 1024 / 1024;
      return gbTransferred * this.costs.bandwidth[costType];
    }
    
    selectOptimal(options, tier) {
      switch (tier) {
        case 'premium':
          // Performance first, cost second
          return options.sort((a, b) => {
            const perfDiff = b.performance.score - a.performance.score;
            if (Math.abs(perfDiff) > 0.1) return perfDiff;
            return a.cost.total - b.cost.total;
          })[0];
        
        case 'standard':
          // Balance performance and cost
          return options.sort((a, b) => {
            const value = (opt) => opt.performance.score / Math.max(0.01, opt.cost.total);
            return value(b) - value(a);
          })[0];
        
        case 'free':
          // Cost first
          return options.sort((a, b) => a.cost.total - b.cost.total)[0];
        
        default:
          return options[0];
      }
    }
    
    async optimizeMonthlyCosts() {
      const usage = await this.getMonthlyUsage();
      const currentCosts = await this.calculateCurrentCosts(usage);
      
      const recommendations = [];
      
      // Check for reserved capacity opportunities
      if (usage.consistent > usage.total * 0.7) {
        recommendations.push({
          type: 'reserved-capacity',
          savings: currentCosts.compute * 0.3,
          action: 'Purchase 1-year reserved instances'
        });
      }
      
      // Check for better routing patterns
      const routingOptimizations = await this.analyzeRoutingPatterns();
      if (routingOptimizations.savings > 100) {
        recommendations.push({
          type: 'routing',
          savings: routingOptimizations.savings,
          action: routingOptimizations.changes
        });
      }
      
      return recommendations;
    }
  }
  ```
- [ ] Setup cost monitoring
- [ ] Configure billing alerts
- [ ] Test cost optimization

### Task 6: Create Traffic Analytics (AC: 6)
- [ ] Build analytics pipeline
  ```javascript
  // services/traffic-analytics.js
  class TrafficAnalytics {
    constructor() {
      this.collectors = {
        realtime: new RealtimeCollector(),
        aggregated: new AggregatedCollector(),
        historical: new HistoricalCollector()
      };
    }
    
    async collectMetrics() {
      return {
        realtime: await this.collectors.realtime.collect(),
        aggregated: await this.collectors.aggregated.collect(),
        patterns: await this.analyzePatterns(),
        anomalies: await this.detectAnomalies()
      };
    }
    
    async analyzePatterns() {
      const data = await this.getTrafficData(24 * 60 * 60 * 1000); // 24 hours
      
      return {
        temporal: this.analyzeTemporalPatterns(data),
        geographic: this.analyzeGeographicPatterns(data),
        service: this.analyzeServicePatterns(data),
        user: this.analyzeUserPatterns(data)
      };
    }
    
    analyzeTemporalPatterns(data) {
      const hourly = new Array(24).fill(0);
      const daily = new Array(7).fill(0);
      
      data.forEach(point => {
        const date = new Date(point.timestamp);
        hourly[date.getHours()] += point.requests;
        daily[date.getDay()] += point.requests;
      });
      
      return {
        peakHours: this.findPeaks(hourly),
        peakDays: this.findPeaks(daily),
        patterns: {
          morning: hourly.slice(6, 12).reduce((a, b) => a + b, 0),
          afternoon: hourly.slice(12, 18).reduce((a, b) => a + b, 0),
          evening: hourly.slice(18, 24).reduce((a, b) => a + b, 0),
          night: hourly.slice(0, 6).reduce((a, b) => a + b, 0)
        }
      };
    }
    
    async detectAnomalies() {
      const current = await this.collectors.realtime.collect();
      const baseline = await this.getBaseline();
      
      const anomalies = [];
      
      // Traffic volume anomaly
      if (Math.abs(current.rps - baseline.rps) > baseline.rps * 0.5) {
        anomalies.push({
          type: 'traffic-volume',
          severity: 'medium',
          current: current.rps,
          expected: baseline.rps,
          deviation: ((current.rps - baseline.rps) / baseline.rps) * 100
        });
      }
      
      // Geographic anomaly
      const geoShift = this.detectGeoShift(current.geographic, baseline.geographic);
      if (geoShift.significant) {
        anomalies.push({
          type: 'geographic-shift',
          severity: 'low',
          details: geoShift
        });
      }
      
      // Error rate anomaly
      if (current.errorRate > baseline.errorRate * 2) {
        anomalies.push({
          type: 'error-spike',
          severity: 'high',
          current: current.errorRate,
          expected: baseline.errorRate
        });
      }
      
      return anomalies;
    }
    
    async generateDashboard() {
      return {
        summary: {
          totalRequests: await this.getTotalRequests(),
          uniqueUsers: await this.getUniqueUsers(),
          avgLatency: await this.getAverageLatency(),
          errorRate: await this.getErrorRate()
        },
        geographic: await this.getGeographicDistribution(),
        endpoints: await this.getEndpointMetrics(),
        trends: await this.getTrends(),
        forecasts: await this.generateForecasts()
      };
    }
  }
  ```
- [ ] Create real-time dashboard
- [ ] Setup alerting
- [ ] Generate reports

### Task 7: Implement Rate Limiting (AC: 7)
- [ ] Configure tiered rate limits
  ```javascript
  // services/rate-limiter.js
  class RateLimiter {
    constructor() {
      this.limits = {
        premium: {
          rps: 1000,
          burst: 2000,
          concurrent: 100,
          daily: 10000000
        },
        standard: {
          rps: 100,
          burst: 200,
          concurrent: 20,
          daily: 1000000
        },
        free: {
          rps: 10,
          burst: 20,
          concurrent: 5,
          daily: 10000
        }
      };
      
      this.buckets = new Map();
      this.slidingWindows = new Map();
    }
    
    async checkLimit(request) {
      const tier = await this.getUserTier(request);
      const limits = this.limits[tier];
      const userId = request.userId;
      
      // Check multiple limit types
      const checks = await Promise.all([
        this.checkRateLimit(userId, limits.rps),
        this.checkBurstLimit(userId, limits.burst),
        this.checkConcurrentLimit(userId, limits.concurrent),
        this.checkDailyLimit(userId, limits.daily)
      ]);
      
      const failed = checks.find(c => !c.allowed);
      
      if (failed) {
        return {
          allowed: false,
          reason: failed.reason,
          retryAfter: failed.retryAfter,
          limit: failed.limit,
          remaining: failed.remaining
        };
      }
      
      return {
        allowed: true,
        remaining: Math.min(...checks.map(c => c.remaining)),
        tier
      };
    }
    
    async checkRateLimit(userId, limit) {
      // Sliding window algorithm
      const window = this.getSlidingWindow(userId);
      const now = Date.now();
      const windowStart = now - 1000; // 1 second window
      
      // Remove old entries
      window.requests = window.requests.filter(t => t > windowStart);
      
      if (window.requests.length >= limit) {
        return {
          allowed: false,
          reason: 'rate_limit_exceeded',
          retryAfter: Math.ceil((window.requests[0] + 1000 - now) / 1000),
          limit,
          remaining: 0
        };
      }
      
      window.requests.push(now);
      
      return {
        allowed: true,
        remaining: limit - window.requests.length
      };
    }
    
    async checkBurstLimit(userId, limit) {
      // Token bucket for burst
      const bucket = this.getTokenBucket(userId);
      const now = Date.now();
      
      // Refill tokens
      const elapsed = now - bucket.lastRefill;
      const refillRate = limit / 10; // Refill over 10 seconds
      const tokensToAdd = (elapsed / 1000) * refillRate;
      
      bucket.tokens = Math.min(limit, bucket.tokens + tokensToAdd);
      bucket.lastRefill = now;
      
      if (bucket.tokens < 1) {
        return {
          allowed: false,
          reason: 'burst_limit_exceeded',
          retryAfter: Math.ceil((1 - bucket.tokens) / refillRate),
          limit,
          remaining: 0
        };
      }
      
      bucket.tokens--;
      
      return {
        allowed: true,
        remaining: Math.floor(bucket.tokens)
      };
    }
    
    async enforce(request, response) {
      const check = await this.checkLimit(request);
      
      // Add rate limit headers
      response.headers.set('X-RateLimit-Limit', check.limit);
      response.headers.set('X-RateLimit-Remaining', check.remaining);
      response.headers.set('X-RateLimit-Reset', check.resetTime);
      
      if (!check.allowed) {
        response.status = 429;
        response.headers.set('Retry-After', check.retryAfter);
        response.body = {
          error: 'Too Many Requests',
          reason: check.reason,
          retryAfter: check.retryAfter
        };
        
        // Log rate limit violation
        await this.logViolation({
          userId: request.userId,
          tier: check.tier,
          reason: check.reason,
          timestamp: new Date()
        });
      }
      
      return response;
    }
  }
  ```
- [ ] Setup distributed rate limiting
- [ ] Configure bypass rules
- [ ] Test rate limiting

### Task 8: Enable Canary Deployments (AC: 8)
- [ ] Implement canary routing
  ```javascript
  // services/canary-router.js
  class CanaryRouter {
    constructor() {
      this.canaries = new Map();
    }
    
    async routeCanary(request) {
      const activeCanary = await this.getActiveCanary();
      
      if (!activeCanary) {
        return this.routeToStable(request);
      }
      
      // Check if user should get canary
      const shouldRouteToCanary = await this.evaluateCanaryRules(request, activeCanary);
      
      if (shouldRouteToCanary) {
        return this.routeToCanary(request, activeCanary);
      }
      
      return this.routeToStable(request);
    }
    
    async evaluateCanaryRules(request, canary) {
      // Check traffic percentage
      if (canary.trafficPercentage) {
        const hash = this.hashRequest(request);
        if (hash % 100 >= canary.trafficPercentage) {
          return false;
        }
      }
      
      // Check user segments
      if (canary.userSegments) {
        const segment = await this.getUserSegment(request);
        if (!canary.userSegments.includes(segment)) {
          return false;
        }
      }
      
      // Check feature flags
      if (canary.featureFlags) {
        const flags = await this.getFeatureFlags(request.userId);
        if (!canary.featureFlags.every(f => flags[f])) {
          return false;
        }
      }
      
      // Check geographic rules
      if (canary.regions) {
        const region = request.headers['cloudfront-viewer-country'];
        if (!canary.regions.includes(region)) {
          return false;
        }
      }
      
      return true;
    }
    
    async deployCanary(config) {
      const canary = {
        id: this.generateId(),
        version: config.version,
        startTime: Date.now(),
        trafficPercentage: config.initialTraffic || 5,
        status: 'deploying',
        metrics: {
          requests: 0,
          errors: 0,
          latency: []
        }
      };
      
      this.canaries.set(canary.id, canary);
      
      // Deploy canary infrastructure
      await this.deployInfrastructure(canary);
      
      // Start with small traffic
      await this.setTrafficPercentage(canary.id, canary.trafficPercentage);
      
      canary.status = 'active';
      
      // Start monitoring
      this.monitorCanary(canary);
      
      return canary;
    }
    
    async promoteCanary(canaryId) {
      const canary = this.canaries.get(canaryId);
      
      console.log(`Promoting canary ${canaryId} to stable`);
      
      // Gradually increase traffic
      const steps = [10, 25, 50, 75, 100];
      
      for (const percentage of steps) {
        await this.setTrafficPercentage(canaryId, percentage);
        
        // Monitor metrics
        await this.sleep(60000); // 1 minute per step
        
        const health = await this.checkCanaryHealth(canary);
        if (!health.healthy) {
          console.log(`Canary unhealthy at ${percentage}%, rolling back`);
          await this.rollbackCanary(canaryId);
          throw new Error(`Canary promotion failed: ${health.reason}`);
        }
      }
      
      // Swap stable and canary
      await this.swapToCanary(canary);
      
      canary.status = 'promoted';
      canary.promotedAt = Date.now();
      
      return canary;
    }
  }
  ```
- [ ] Setup canary monitoring
- [ ] Configure auto-rollback
- [ ] Test canary scenarios

---

## Dev Notes

### Load Balancing Algorithms
```
Round Robin: Simple rotation
Least Connections: Route to least busy
Weighted Response Time: Favor faster endpoints
Geographic: Nearest endpoint
Cost Optimized: Cheapest route
```

### Traffic Tiers
```
Premium: Unlimited bandwidth, Priority 1, < 50ms target
Standard: 100 Mbps, Priority 2, < 100ms target
Free: 10 Mbps, Priority 3, < 200ms target
```

### Rate Limits
```
Premium: 1000 RPS, 2000 burst, 100 concurrent
Standard: 100 RPS, 200 burst, 20 concurrent
Free: 10 RPS, 20 burst, 5 concurrent
```

### Canary Progression
```
5% → 10% → 25% → 50% → 75% → 100%
1 min monitoring between steps
Auto-rollback on error spike
```

### Testing Standards
- Test location: `/tests/distribution/traffic/`
- Test load balancing algorithms
- Verify QoS enforcement
- Test rate limiting
- Monitor canary deployments

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-09-22 | 1.0 | Initial story creation | Bob (SM) |

---

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent_

### Debug Log References
_To be populated during development_

### Completion Notes List
_To be populated during development_

### File List
_To be populated during development_

---

## QA Results
_To be populated by QA agent_