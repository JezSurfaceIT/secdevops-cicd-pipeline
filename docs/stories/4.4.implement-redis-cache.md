# Story 4.4: Implement Redis Cache

**Epic:** 4 - Production SaaS Deployment  
**Story Number:** 4.4  
**Title:** Configure Redis Cache for Session and Data Caching  
**Status:** READY  
**Points:** 3  
**Component:** 713 (Redis Cache)  

---

## Story

**As a** Performance Engineer,  
**I want** Redis caching for sessions and frequently accessed data,  
**so that** application performance is optimized and database load is reduced.

---

## Acceptance Criteria

1. Azure Cache for Redis Premium tier deployed
2. Clustering enabled for scalability
3. Redis persistence configured for data durability
4. Private endpoint in subnet 10.20.5.0/24
5. Session management implemented
6. Cache-aside pattern for data caching
7. Redis Sentinel for high availability
8. Monitoring and alerting configured

---

## Tasks / Subtasks

### Task 1: Write Cache Tests (TDD) (AC: 1, 4, 5)
- [ ] Create `production/redis_test.go`
  - [ ] Test Redis deployment successful
  - [ ] Test private endpoint accessible
  - [ ] Test session storage works
  - [ ] Test cache operations
- [ ] Run tests to confirm they fail (Red phase)

### Task 2: Deploy Redis Infrastructure (AC: 1, 2, 3)
- [ ] Create Azure Cache for Redis
  ```hcl
  resource "azurerm_redis_cache" "main" {
    name                = "redis-oversight-prod"
    location            = var.location
    resource_group_name = "rg-oversight-prod-saas-eastus"
    
    sku_name   = "Premium"
    family     = "P"
    capacity   = 1  # 6GB
    
    # Clustering
    shard_count = 2
    
    # Redis configuration
    redis_configuration {
      enable_authentication         = true
      maxmemory_policy             = "allkeys-lru"
      maxmemory_reserved           = 10
      maxfragmentationmemory_reserved = 10
      
      # Persistence
      rdb_backup_enabled           = true
      rdb_backup_frequency         = 60  # Every hour
      rdb_backup_max_snapshot_count = 5
      rdb_storage_connection_string = azurerm_storage_account.redis_backup.primary_connection_string
      
      # AOF persistence
      aof_backup_enabled          = true
      aof_storage_connection_string_0 = azurerm_storage_account.redis_backup.primary_connection_string
      aof_storage_connection_string_1 = azurerm_storage_account.redis_backup.secondary_connection_string
      
      # Performance
      maxclients = 7500
      
      # Notifications
      notify_keyspace_events = "Ex"
    }
    
    # Network
    subnet_id = azurerm_subnet.saas_redis.id
    
    # Zones for HA
    zones = ["1", "2"]
    
    # Patch schedule
    patch_schedule {
      day_of_week    = "Sunday"
      start_hour_utc = 2
    }
    
    tags = {
      environment = "production"
      component   = "cache"
      ha_enabled  = "true"
    }
  }
  
  # Create firewall rules if needed
  resource "azurerm_redis_firewall_rule" "app_service" {
    name                = "app-service-access"
    redis_cache_name    = azurerm_redis_cache.main.name
    resource_group_name = "rg-oversight-prod-saas-eastus"
    start_ip           = "10.20.2.0"
    end_ip             = "10.20.2.255"
  }
  ```
- [ ] Configure geo-replication
  ```hcl
  resource "azurerm_redis_cache" "secondary" {
    name                = "redis-oversight-prod-secondary"
    location            = "westus"
    resource_group_name = "rg-oversight-prod-saas-westus"
    
    sku_name   = "Premium"
    family     = "P"
    capacity   = 1
    
    redis_configuration {
      # Same configuration as primary
    }
  }
  
  resource "azurerm_redis_linked_server" "geo_replication" {
    target_redis_cache_name   = azurerm_redis_cache.main.name
    resource_group_name       = "rg-oversight-prod-saas-eastus"
    linked_redis_cache_id     = azurerm_redis_cache.secondary.id
    linked_redis_cache_location = azurerm_redis_cache.secondary.location
    server_role              = "Secondary"
  }
  ```
- [ ] Setup backup storage
- [ ] Configure access keys in Key Vault

### Task 3: Configure Private Endpoint (AC: 4)
- [ ] Create private endpoint
  ```hcl
  resource "azurerm_private_endpoint" "redis" {
    name                = "pe-redis"
    location            = var.location
    resource_group_name = "rg-oversight-prod-saas-eastus"
    subnet_id           = azurerm_subnet.saas_redis.id
    
    private_service_connection {
      name                           = "psc-redis"
      private_connection_resource_id = azurerm_redis_cache.main.id
      subresource_names             = ["redisCache"]
      is_manual_connection          = false
    }
    
    private_dns_zone_group {
      name                 = "pdz-group-redis"
      private_dns_zone_ids = [azurerm_private_dns_zone.redis.id]
    }
  }
  
  resource "azurerm_private_dns_zone" "redis" {
    name                = "privatelink.redis.cache.windows.net"
    resource_group_name = "rg-oversight-prod-saas-eastus"
  }
  ```
- [ ] Test private connectivity
- [ ] Configure DNS resolution
- [ ] Disable public access

### Task 4: Implement Session Management (AC: 5)
- [ ] Configure session storage
  ```javascript
  // config/session.js
  const session = require('express-session');
  const RedisStore = require('connect-redis')(session);
  const { createClient } = require('redis');
  const secretManager = require('./secrets');
  
  class SessionManager {
    async initialize(app) {
      // Get Redis connection from Key Vault
      const redisConfig = await secretManager.getRedisConfig();
      
      // Create Redis client
      this.redisClient = createClient({
        socket: {
          host: redisConfig.host,
          port: redisConfig.port,
          tls: true
        },
        password: redisConfig.password,
        database: 0,  // Use DB 0 for sessions
        
        // Connection pool
        pool: {
          min: 2,
          max: 10
        },
        
        // Retry strategy
        retry_strategy: (options) => {
          if (options.error && options.error.code === 'ECONNREFUSED') {
            return new Error('Redis connection refused');
          }
          if (options.total_retry_time > 1000 * 60 * 60) {
            return new Error('Redis retry time exhausted');
          }
          if (options.attempt > 10) {
            return undefined;
          }
          return Math.min(options.attempt * 100, 3000);
        }
      });
      
      await this.redisClient.connect();
      
      // Configure session middleware
      app.use(session({
        store: new RedisStore({
          client: this.redisClient,
          prefix: 'sess:',
          ttl: 86400  // 24 hours
        }),
        
        secret: await secretManager.getSecret('session-secret'),
        resave: false,
        saveUninitialized: false,
        rolling: true,
        
        cookie: {
          secure: true,  // HTTPS only
          httpOnly: true,
          maxAge: 86400000,  // 24 hours
          sameSite: 'strict'
        },
        
        name: 'oversight.sid',
        
        genid: () => {
          return `${Date.now()}-${crypto.randomBytes(16).toString('hex')}`;
        }
      }));
      
      // Session cleanup job
      this.startSessionCleanup();
    }
    
    async startSessionCleanup() {
      setInterval(async () => {
        try {
          // Clean expired sessions
          const keys = await this.redisClient.keys('sess:*');
          for (const key of keys) {
            const ttl = await this.redisClient.ttl(key);
            if (ttl === -1) {  // No expiry set
              await this.redisClient.expire(key, 86400);
            }
          }
        } catch (error) {
          console.error('Session cleanup error:', error);
        }
      }, 3600000);  // Every hour
    }
  }
  
  module.exports = new SessionManager();
  ```
- [ ] Implement session security
- [ ] Configure session clustering
- [ ] Test session failover

### Task 5: Implement Data Caching (AC: 6)
- [ ] Create cache service
  ```javascript
  // services/cache.js
  const { createClient } = require('redis');
  const hash = require('object-hash');
  
  class CacheService {
    constructor() {
      this.client = null;
      this.defaultTTL = 3600;  // 1 hour
    }
    
    async initialize() {
      const redisConfig = await secretManager.getRedisConfig();
      
      this.client = createClient({
        socket: {
          host: redisConfig.host,
          port: redisConfig.port,
          tls: true
        },
        password: redisConfig.password,
        database: 1  // Use DB 1 for data cache
      });
      
      await this.client.connect();
      
      // Event handlers
      this.client.on('error', (err) => console.error('Redis error:', err));
      this.client.on('reconnecting', () => console.log('Redis reconnecting...'));
    }
    
    // Cache-aside pattern
    async get(key, fetchFunction, options = {}) {
      try {
        // Try to get from cache
        const cached = await this.client.get(key);
        
        if (cached) {
          console.log(`Cache hit: ${key}`);
          return JSON.parse(cached);
        }
        
        console.log(`Cache miss: ${key}`);
        
        // Fetch from source
        const data = await fetchFunction();
        
        // Store in cache
        const ttl = options.ttl || this.defaultTTL;
        await this.set(key, data, ttl);
        
        return data;
      } catch (error) {
        console.error('Cache error:', error);
        // Fallback to fetch function
        return await fetchFunction();
      }
    }
    
    async set(key, value, ttl = this.defaultTTL) {
      const serialized = JSON.stringify(value);
      await this.client.setEx(key, ttl, serialized);
    }
    
    async delete(key) {
      await this.client.del(key);
    }
    
    async invalidatePattern(pattern) {
      const keys = await this.client.keys(pattern);
      if (keys.length > 0) {
        await this.client.del(keys);
      }
    }
    
    // Memoization decorator
    memoize(fn, options = {}) {
      return async (...args) => {
        const key = `memo:${fn.name}:${hash(args)}`;
        return await this.get(key, () => fn(...args), options);
      };
    }
    
    // Batch operations
    async multiGet(keys) {
      const pipeline = this.client.pipeline();
      keys.forEach(key => pipeline.get(key));
      const results = await pipeline.exec();
      
      return results.map((result, index) => ({
        key: keys[index],
        value: result[1] ? JSON.parse(result[1]) : null
      }));
    }
    
    // Cache warming
    async warmCache(items) {
      const pipeline = this.client.pipeline();
      
      items.forEach(({ key, value, ttl }) => {
        pipeline.setEx(key, ttl || this.defaultTTL, JSON.stringify(value));
      });
      
      await pipeline.exec();
    }
  }
  
  module.exports = new CacheService();
  ```
- [ ] Implement cache strategies
  ```javascript
  // strategies/caching-strategies.js
  class CachingStrategies {
    // Write-through cache
    async writeThrough(key, value, dbWriteFunc) {
      await dbWriteFunc(value);
      await cache.set(key, value);
      return value;
    }
    
    // Write-behind cache
    async writeBehind(key, value, dbWriteFunc) {
      await cache.set(key, value);
      
      // Queue for async write
      queue.push({
        action: 'write',
        func: dbWriteFunc,
        data: value,
        timestamp: Date.now()
      });
      
      return value;
    }
    
    // Refresh-ahead cache
    async refreshAhead(key, fetchFunc, threshold = 0.8) {
      const ttl = await cache.client.ttl(key);
      const maxTtl = cache.defaultTTL;
      
      if (ttl < maxTtl * threshold) {
        // Refresh in background
        setImmediate(async () => {
          const fresh = await fetchFunc();
          await cache.set(key, fresh);
        });
      }
      
      return await cache.get(key);
    }
  }
  ```
- [ ] Setup cache invalidation
- [ ] Monitor cache hit rates

### Task 6: Configure High Availability (AC: 7)
- [ ] Setup Redis Sentinel
  ```yaml
  # docker-compose.sentinel.yml
  version: '3.8'
  services:
    sentinel1:
      image: redis:7-alpine
      command: redis-sentinel /etc/redis/sentinel.conf
      volumes:
        - ./sentinel1.conf:/etc/redis/sentinel.conf
      networks:
        - redis-ha
    
    sentinel2:
      image: redis:7-alpine
      command: redis-sentinel /etc/redis/sentinel.conf
      volumes:
        - ./sentinel2.conf:/etc/redis/sentinel.conf
      networks:
        - redis-ha
    
    sentinel3:
      image: redis:7-alpine
      command: redis-sentinel /etc/redis/sentinel.conf
      volumes:
        - ./sentinel3.conf:/etc/redis/sentinel.conf
      networks:
        - redis-ha
  ```
- [ ] Configure automatic failover
- [ ] Test failover scenarios
- [ ] Setup connection retry logic

### Task 7: Implement Monitoring (AC: 8)
- [ ] Configure diagnostics
  ```hcl
  resource "azurerm_monitor_diagnostic_setting" "redis" {
    name               = "diag-redis"
    target_resource_id = azurerm_redis_cache.main.id
    
    log_analytics_workspace_id = azurerm_log_analytics_workspace.main.id
    
    metric {
      category = "AllMetrics"
      retention_policy {
        enabled = true
        days    = 30
      }
    }
  }
  ```
- [ ] Create monitoring dashboard
  ```javascript
  // monitoring/redis-metrics.js
  class RedisMonitoring {
    async collectMetrics() {
      const info = await cache.client.info();
      const stats = this.parseInfo(info);
      
      return {
        memory: {
          used: stats.used_memory,
          peak: stats.used_memory_peak,
          fragmentation: stats.mem_fragmentation_ratio
        },
        
        performance: {
          ops_per_sec: stats.instantaneous_ops_per_sec,
          hit_rate: stats.keyspace_hits / (stats.keyspace_hits + stats.keyspace_misses),
          evicted_keys: stats.evicted_keys
        },
        
        connections: {
          connected: stats.connected_clients,
          blocked: stats.blocked_clients,
          rejected: stats.rejected_connections
        },
        
        persistence: {
          last_save: stats.rdb_last_save_time,
          changes_since_save: stats.rdb_changes_since_last_save,
          aof_rewrite_in_progress: stats.aof_rewrite_in_progress
        }
      };
    }
  }
  ```
- [ ] Setup alerts
- [ ] Create performance reports

---

## Dev Notes

### Redis Configuration
```
Primary Endpoint: redis-oversight-prod.redis.cache.windows.net:6380
Private Endpoint: 10.20.5.4:6380
SSL/TLS: Required
Auth: Password from Key Vault
Databases: 16 (0=sessions, 1=cache, 2=queues)
```

### Cache Keys Convention
```
Format: {namespace}:{entity}:{id}:{field}
Examples:
- user:profile:123:data
- product:catalog:456:details
- session:user:789:cart
- cache:api:endpoint:/users:page1
```

### Testing Standards
- Test location: `/tests/production/cache/`
- Test cache operations
- Verify session management
- Test failover scenarios
- Monitor performance impact

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-09-22 | 1.0 | Initial story creation | Bob (SM) |

---

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent_

### Debug Log References
_To be populated during development_

### Completion Notes List
_To be populated during development_

### File List
_To be populated during development_

---

## QA Results
_To be populated by QA agent_